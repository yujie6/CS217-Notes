\documentclass[12pt,a4]{article}

\newcommand{\handoutdate}{Friday, 2020-04-17}
\newcommand{\firstduedate}{Friday, 2019-04-24}
\newcommand{\finalduedate}{Tuesday, 2020-05-01}


\input{preamble}

\setcounter{section}{3}

\section{Bottleneck Paths}

Let $G=(V,E)$ be a directed graph with an edge capacity function $c: E \rightarrow \R^+$. For a path
$p = u_0 u_1 \dots u_t$ define its {\em capacity} to be
\begin{align}
   c(p) := \min_{1 \leq i \leq t} c( \{u_{i-1}, u_i\}) \ .
\end{align}

\begin{quotation}
    \textbf{Maximum Capacity Path Problem (MCP).} Given a directed graph $G = (V,E)$, an edge capacity function
    $c: E \rightarrow \R^+$, and two vertices $s, t \in V$, compute the path $p^*$ maximizing $c(p)$. We
    denote by $p^*$ the optimal path and by $c^* := c(p^*)$ its cost. 
\end{quotation}



\begin{exercise}
   Suppose the edges $e_1,\dots,e_m$ are sorted by their cost. Show how to solve MCP in time $O(n+m)$.
\end{exercise}

\begin{proof}
Design a algorithm following Pseudocode shows(Suppose the edges are sorted decreased, See in Algorithm 1):

And then we think about the correctness and complexity.

The algorithm means we can enum the answer. When we find a edge between the point visited and not visited, we can go through all the edges which's costs is higher than this edge. If now s is connected to t, means this edge is the largest edge while going through all edges higher than it from $s$ to $t$. That fits the answer we want.

Now, let's think about the complexity. For every node, it may be in queue at least once. And for every edge, it may be in $G'$ and used in bfs at least once. So the time complexity is $O(n+m)$.
\begin{algorithm}[H]
\caption{Solve MCP in time $\Theta(n+m)$ with all the edges sorted by their cost}
\begin{algorithmic}
\Procedure{MCP}{$G, s, t$}
	\State Initiate $visited \gets s$ and $G' \leftarrow \emptyset$
	\For {$e \in G$}
		\If{$e.from\in visited$ and $e.to\notin visited$}
			\State $bfs\_graph(e.to, G')$
		\Else
			\State $G'\gets G' \cup {e}$
		\EndIf
		\If{$t \in visited$}
			\State \Return $e.weight$
		\EndIf
	\EndFor
\EndProcedure
\Procedure{bfs\_graph}{$s, G$}
	\State $visited \gets visited \cup {s}$
	\State push s into the queue
	\While {queue is not empty}
		\State Let top be the head of the queue and pop the head.
		\For{$e \in {edges\ in\ G\ from\ top}$}
			\If {$e.to \notin visited$}
				\State $visited \gets visitied \cup{e.to}$
				\State push e.to into the queue
			\EndIf
		\EndFor
	\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}
\end{proof}

\begin{exercise}
   Give an algorithm for MCP of running time $O(m \log \log m)$. \textbf{Hint:} Using the median-of-medians algorithm,
   you can determine an edge $e$ such that at most $m/2$ edges are cheaper than $e$ and at most $m/2$ edges are
   more expensive than $e$. Can you determine, in time $O(n+m)$, whether $c^* < c(e)$, $c^* = c(e)$, or $c^* > c(e)$?
   Iterate to shrink the set of possible
    values for $c^*$ to $m/4$, $m/8$, and so on.
\end{exercise}
\begin{proof}
	As is shown by the hint, during each iteration, we can shrink the
	set of possible values of $c^{*}$, i.e. 
	\[
E_1= \{e \mid c\left( e \right) \le M,e\in E'\}, 
		E_2 = \{e \mid c\left( e \right) > M, e\in E'\}
		\]
	We we can find a path in  $E_2$, then the lower bound $L$ of $c^{*}$ can 
	be updated to $M$. Since if $c^{*}>L$, we must have a 
	path $e$ with all the edges larger then $L$.

	Otherwise, the upper bound $U$ will be $M$ as there is no such path with 
	all edges larger than $M$. However, if we take iterations until 
	$L = U$, we will have $O\left( m\log m  \right)  $ running time. So we only do 
	$ \log(s\left( m \right) )$ 
	iterations. Here $s$ is a place holder to decide later

	Consider the following algorithm
	\begin{algorithm}[H]
		\caption{Solve MCP in time $n\log\log n$ }
		\begin{algorithmic}
				\State $i=0, U = \infty, L = 0$
				\While {$i < \log s\left( m \right) $ }
				\State Determine the median of $\{e \mid e\in E',c\left( e \right) \le U\} $.
				\If{ $\left( V,E_2 \right) $ is $s$- $t$ connected }
				\State $E' \leftarrow E_2, L = M$,
				\Else 
				\State $U = M$
				\EndIf
				\State $i=i+1$
				\EndWhile	
				\State Number $t$ edges in set $\{e \in E' \mid c\left( e \right) \le U\} $ according to increasing order $e_1,e_2,\ldots.$
				\State Solve instance by \textbf{Algorithm 1} with the following 
				ordering, i.e. the place of $e$ in the sorted array 
				\[
						l\left( e \right) = \begin{cases}
								1, \quad c\left( e \right) \le L \\
								i, \quad  \exists i,e =e_{i} \\
								t, \quad c \left( e \right) > U
						\end{cases}
				.\] 
		\end{algorithmic}
\end{algorithm}
Now we prove this algotihm is $n\log \log n$, just notice that 
\[
		t = O\left( \frac{m}{s\left( m \right) } \right) 
.\] 
Since every iteration we make the set $\{ e  \mid  e\in E', c\left( e \right) 
< U\} $ shrinks to $\frac{1}{2}$. That is 
the size $t = \lvert  E'\rvert \le \frac{m}{2^{\log s\left( m \right) }}$. 

Thus the running time is 
\[
\log\left( s\left( m \right) \right)\cdot m + t \log t + t
\]
considering the sorting of the 
$t$ edges plus the running time of \textbf{Algorithm 1} ,
now we choose $s\left( m \right) = \log m $ to minimize the time which is 
\[
		m\left( \frac{\log m}{s} - \frac{\log s}{s} \right) 
.\] 
Hence 
\[
		T =O\left( m \log\log m \right) + O \left( \frac{m}{\log m} \log \left( \frac{m}{\log m } \right) \right) + 
		O \left( \log m \right) 
		= O\left( m\log\log m  \right) 
.\] 
\end{proof}


\begin{exercise}
   Give an algorithm for MCP that runs in time $O(m \log \log \log m)$? How about $O(m \log \log \log \log m)$? How far can you get?
\end{exercise}
\begin{proof}
		We can have a better algorithm runs in $O\left( m \log\ldots\log m \right) $ (arbitrary number of log), 

		Consider a set of edge $E$ with $\frac{m}{k}$ elements. We apply  \textbf{median of median} algorithm
		$k$ rounds. Each round we break one block into 2 parts. For example, in the first round, we find the median 
		 $M$ of $E$, and break $E$ into
		\[
				E_1=\{e \mid c\left( e \right) < M, e\in E\} , E_2 = \{e  \mid c \left( e \right) \ge M, e\in E\} 
		.\] 
		And in the second round, we can obtain 4 blocks by apply MOM to $E_1,E_2$ respectively. Finally we have $2^{k}$ blocks $A_1,\ldots,A_{2^{k}}$ by using the above method
		recursively, while
		each block has $\frac{m}{k 2^{k}}$ elements. Plus by the property of median
		\[
				\forall i<j, \forall e_1 \in A_i, e_2\in A_j, c\left( e_1 \right) < c\left( e_2 \right) 
		.\] 
		Hence we can apply the idea we used in \textbf{Exercise 2}. That is, 

	\begin{algorithm}[H]
		\caption{The key idea to solve MCP in time $n\log\ldots\log n$ }
		\begin{algorithmic}
				\State $E' = \bigcup_{i\le 2^{k}} A_{i}, L = 0, U = \max\left( E \right) $
				\For{$i$ in range$(2^{k})$}
				\If{ $\left( V,A_i \right) $ is $s$- $t$ connected}
				\State $E' \leftarrow A_i$, $L = \min \left( A_i \right) $ 
				\Else 
				\State $U = \min \left( A_i \right) $
				\EndIf
				\EndFor	
		\end{algorithmic}
\end{algorithm}
Hence our problem is reduced to a edge set $E'$ with whose size is $O\left( \frac{m}{k 2^{k}} \right) $, we
call this one  iteration. And this 
costs 
 \[
		 T = \sum_{i=1}^{k} \sum_{j=1}^{i} O\left( \frac{m}{k 2^{i}} \right) = k O\left( \frac{m}{k} \right) = O\left( m \right) 
.\] 
And let $f\left( k \right)  = k 2^{k}$, assume that after $r$ iterations, we can decide $c^{*}$ i.e. there is only one integer in the interval $E'$, we have 
\[
		f^{r-1}\left( 1 \right) <  m \le  f^{r} \left( 1 \right) 
.\] 
Which leads that $m \ge g^{r-1}\left( 1 \right)  $, in which $g\left( x \right) = 2^{x}$. Hence $r$ is the 
smallest integer such that 
$1 \le  \log \log\ldots\log m$ with $r$ log, that means we only need 
$r$ iterations to reduce the problem,  hence the overall running time is 
$O\left( r m  \right)  $. Actually we can prove $\forall s$, $\exists m$
\[
		r < \log\log\ldots\log m \left( \text{with } s \log \right) 
.\] 
Otherwise $1 < \log\ldots\log r $ with $r-s$ log. Hence  $r >f^{r-s} \left( 1 \right) $, which
leads to a contradiction since $m$ and  $r$ can be arbitrarily large but $s$ is fixed.
Hence the running time could be written as $O\left( m \log \log \ldots\log m \right) $ (arbitrary number of log). 
\end{proof}

\end{document}
